{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FuMGHtL6wWx2ceZItxZpCIqGkqFsb9FT",
      "authorship_tag": "ABX9TyOUtJ1IAHEZVppky5tXMwqc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConradKatlegoMogane/DPSA_Circular_data_mining/blob/main/Government_Circulars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 0: Install required libraries\n",
        "# ------------------------------------------------------------\n",
        "# PyMuPDF (fitz) → PDF text extraction\n",
        "# pandas → tabular storage and analysis\n",
        "%pip install pymupdf pandas\n"
      ],
      "metadata": {
        "id": "eqduENvZaQa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 0.1: Import libraries\n",
        "# ------------------------------------------------------------\n",
        "import fitz        # PyMuPDF for PDF handling\n",
        "import re          # Regular expressions for text parsing\n",
        "import pandas as pd  # Tabular data manipulation\n"
      ],
      "metadata": {
        "id": "9CiWcD3QaTwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 1: Load the PDF document and extract text\n",
        "# ------------------------------------------------------------\n",
        "doc = fitz.open(r\"/content/drive/MyDrive/DPSA_cIRCULARS/PSV CIRCULAR 40 OF 2025.pdf\")\n",
        "\n",
        "# Concatenate text from all pages\n",
        "text = \"\"\n",
        "for page in doc:\n",
        "    text += page.get_text()\n",
        "\n",
        "doc.close()  # Always close the document after extraction\n"
      ],
      "metadata": {
        "id": "8YDVQLrCaVtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 2: Split text into individual job posts\n",
        "# ------------------------------------------------------------\n",
        "# Each post begins with \"POST <number>/<year>:\"\n",
        "posts = re.split(r\"\\nPOST\\s+\\d+/\\d+\\s*:\\s*\", text)[1:]  # skip header\n"
      ],
      "metadata": {
        "id": "Oo0Xi6YdaS05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 3: Extract fields from each post using regex\n",
        "# ------------------------------------------------------------\n",
        "data = []\n",
        "for post_text in posts:\n",
        "    try:\n",
        "        # Job title (first line)\n",
        "        post_match = re.search(r\"^(.*?)\\n\", post_text)\n",
        "\n",
        "        # Centre\n",
        "        centre_match = re.search(r\"CENTRE\\s*:\\s*(.*)\", post_text)\n",
        "\n",
        "        # Salary or Stipend\n",
        "        salary_match = re.search(r\"(?:SALARY|STIPEND)\\s*:\\s*(.*)\", post_text)\n",
        "\n",
        "        # Requirements (until \"DUTIES\")\n",
        "        requirements_match = re.search(r\"REQUIREMENTS\\s*:\\s*(.*?)(?:DUTIES\\s*:)\", post_text, re.DOTALL)\n",
        "\n",
        "        # Duties (until \"ENQUIRIES\")\n",
        "        duties_match = re.search(r\"DUTIES\\s*:\\s*(.*?)(?:ENQUIRIES\\s*:)\", post_text, re.DOTALL)\n",
        "\n",
        "        # Enquiries\n",
        "        enquiries_match = re.search(r\"ENQUIRIES\\s*:\\s*(.*)\", post_text)\n",
        "\n",
        "        # Closing Date (applies to entire document)\n",
        "        closing_match = re.search(r\"CLOSING DATE\\s*:\\s*(.*)\", text)\n",
        "\n",
        "        # Clean and store values\n",
        "        post = post_match.group(1).strip() if post_match else \"\"\n",
        "        centre = centre_match.group(1).strip() if centre_match else \"\"\n",
        "        salary = salary_match.group(1).strip() if salary_match else \"\"\n",
        "        requirements = requirements_match.group(1).strip().replace(\"\\n\", \" \") if requirements_match else \"\"\n",
        "        duties = duties_match.group(1).strip().replace(\"\\n\", \" \") if duties_match else \"\"\n",
        "        enquiries = enquiries_match.group(1).strip() if enquiries_match else \"\"\n",
        "        closing_date = closing_match.group(1).strip() if closing_match else \"\"\n",
        "\n",
        "        # Append structured record\n",
        "        data.append({\n",
        "            \"Post\": post,\n",
        "            \"Centre\": centre,\n",
        "            \"Salary\": salary,\n",
        "            \"Requirements\": requirements,\n",
        "            \"Duties\": duties,\n",
        "            \"Enquiries\": enquiries,\n",
        "            \"Closing Date\": closing_date\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error processing a post: {e}\")\n",
        "        continue\n"
      ],
      "metadata": {
        "id": "I8PuU3Shae5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 4: Convert extracted data into a DataFrame\n",
        "# ------------------------------------------------------------\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Export to Excel for external use\n",
        "df.to_excel('dpsa_excel.xlsx')\n",
        "\n",
        "# Display last record for verification\n",
        "df.tail(1)\n"
      ],
      "metadata": {
        "id": "F3R1eunoae2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 5: Extract structured salary details\n",
        "# ------------------------------------------------------------\n",
        "import numpy as np\n",
        "\n",
        "def extract_salary_details(salary_str):\n",
        "    \"\"\"\n",
        "    Extracts min, max salary, and salary level from a given salary string.\n",
        "    Returns a tuple: (min_salary, max_salary, salary_level).\n",
        "    \"\"\"\n",
        "    min_salary, max_salary = np.nan, np.nan\n",
        "    salary_level = None\n",
        "\n",
        "    if pd.isna(salary_str):\n",
        "        return (min_salary, max_salary, salary_level)\n",
        "\n",
        "    original_salary_str = str(salary_str).lower().strip()\n",
        "    temp_salary_str = original_salary_str\n",
        "\n",
        "    # Remove parentheses and 'per annum'\n",
        "    temp_salary_str = re.sub(r'\\s*\\(.*\\)', '', temp_salary_str)\n",
        "    temp_salary_str = re.sub(r'\\s*per\\s+annum.*', '', temp_salary_str)\n",
        "\n",
        "    # Remove 'R' and commas\n",
        "    temp_salary_str = temp_salary_str.replace('r', '').replace(',', '')\n",
        "\n",
        "    # Extract numeric ranges\n",
        "    if '–' in temp_salary_str or '-' in temp_salary_str:\n",
        "        range_numbers_str = re.findall(r'\\d+(?:\\s*\\d+)*(?:\\.\\d+)?', temp_salary_str)\n",
        "        if len(range_numbers_str) >= 2:\n",
        "            try:\n",
        "                min_salary = float(range_numbers_str[0].replace('\\xa0', ''))\n",
        "                max_salary = float(range_numbers_str[1].replace('\\xa0', ''))\n",
        "            except ValueError:\n",
        "                pass\n",
        "    else:\n",
        "        numbers_str = ''.join(re.findall(r'\\d+(?:\\s*\\d+)*(?:\\.\\d+)?', temp_salary_str)).replace('\\xa0', '')\n",
        "        try:\n",
        "            min_salary = float(numbers_str)\n",
        "        except (ValueError, TypeError):\n",
        "            pass\n",
        "\n",
        "    # Extract salary level\n",
        "    level_match = re.search(r'level\\s*(\\d+|[A-Z])', original_salary_str, re.IGNORECASE)\n",
        "    if level_match:\n",
        "        salary_level = level_match.group(1).strip()\n",
        "\n",
        "    return (min_salary, max_salary, salary_level)\n",
        "\n",
        "# Apply to DataFrame\n",
        "df[['Min_Salary', 'Max_Salary', 'Salary_Level']] = df['Salary'].apply(extract_salary_details).apply(pd.Series)\n",
        "\n",
        "# Display results\n",
        "display(df[['Post', 'Salary', 'Min_Salary', 'Max_Salary', 'Salary_Level']])\n"
      ],
      "metadata": {
        "id": "yCwle5Xdaezt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 6: Extract NQF levels and qualifications\n",
        "# ------------------------------------------------------------\n",
        "def extract_nqf_info(requirements_str):\n",
        "    \"\"\"\n",
        "    Extracts NQF level(s) and qualifications from a requirements string.\n",
        "    Handles explicit mentions (e.g., 'NQF Level 6') and implicit qualifications (LLB, Grade 12, etc.).\n",
        "    Returns a tuple: (levels, qualifications).\n",
        "    \"\"\"\n",
        "    if pd.isna(requirements_str):\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    levels = set()\n",
        "\n",
        "    # Explicit NQF matches\n",
        "    explicit_nqf_matches = re.findall(r'(?:NQF\\s*[-_]?Level|Level|NQF)\\s*(\\d+)', requirements_str, re.IGNORECASE)\n",
        "    for m in explicit_nqf_matches:\n",
        "        levels.add(int(m))\n",
        "\n",
        "    # Mapping dictionary\n",
        "    nqf_map = {\n",
        "        1: \"Grade 9 / GETC (ABET Level 4)\",\n",
        "        2: \"Grade 10 / NC(V) Level 2\",\n",
        "        3: \"Grade 11 / NC(V) Level 3\",\n",
        "        4: \"Grade 12 / NSC or NC(V) Level 4\",\n",
        "        5: \"Higher Certificate\",\n",
        "        6: \"Diploma / Advanced Certificate\",\n",
        "        7: \"Bachelor’s Degree / Advanced Diploma\",\n",
        "        8: \"Honours Degree / Postgraduate Diploma / LLB / MBChB / Medical Practitioner\",\n",
        "        9: \"Master’s Degree / MMed / Medical Specialist\",\n",
        "        10: \"Doctoral Degree (PhD)\"\n",
        "    }\n",
        "\n",
        "    qualifications = [nqf_map.get(l, \"\") for l in sorted(list(levels))]\n",
        "    return (list(levels) if levels else np.nan, qualifications if qualifications else np.nan)\n",
        "\n",
        "# Apply row-wise\n",
        "df[['NQF Level', 'Qualifications']] = df['Requirements'].apply(lambda x: pd.Series(extract_nqf_info(x)))\n"
      ],
      "metadata": {
        "id": "aTUQLucuaeod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Step 7: Display NQF and Qualification counts side by side\n",
        "# ------------------------------------------------------------\n",
        "from IPython.display import HTML\n",
        "\n",
        "def side_by_side(*dfs):\n",
        "    \"\"\"Display multiple pandas DataFrames side by side in Jupyter Notebook.\"\"\"\n",
        "    html = '<div style=\"display:flex\">'\n",
        "    for df in dfs:\n",
        "        html += '<div style=\"margin-right:2em\">'\n",
        "        html += df.to_html()\n",
        "        html += '</div>'\n",
        "    html += '</div>'\n",
        "    display(HTML(html))\n",
        "\n",
        "# Show missing percentages\n",
        "print(f\"{((df['Qualifications'].isna().sum() / len(df)) * 100).round(1)} % Qualifications rows still empty\")\n",
        "print(f\"{((df['NQF Level"
      ],
      "metadata": {
        "id": "mxUh7ejbar4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}